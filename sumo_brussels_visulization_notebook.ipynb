{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3132c2a",
   "metadata": {},
   "source": [
    "# SUMO Brussels — Visualization Notebook\n",
    "\n",
    "This notebook is prepared for analysing and visulizating SUMO outputs from the experimental Brussels traffic scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cac1bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMO Brussels — Visualization Notebook\n",
    "# Repository: https://github.com/aed90/SUMO-Brussels-Visualization-Notebook\n",
    "\n",
    "\"\"\"\n",
    "This notebook provides:\n",
    "- A reproducible walkthrough to load any SUMO repo, detect networks and sumo output types within it.\n",
    "- All necessary details to understand the simulation outputs meaningfully with summaries, plots, and map graphs.\n",
    "- Uses SUMO's visualization tools from <SUMO_HOME>/tools/visualization.\n",
    "- Contains both command-line usages and python code for custom plots.\n",
    "- Users can adjust various arguments, such as the target simulation repository, the repository structure, and the local output directory, and thresholds for any other simulation repository testing.\n",
    "- If a sumo output type is not found, the notebook does not fail and simply skips it.\n",
    "\n",
    "The tool provides:\n",
    "\n",
    "1. Statistical Summary: Aggregated performance metrics and stats.\n",
    "2. Operational Checks: Vehicle movement rationality.\n",
    "3. Detector Validation: Sensor functionality.\n",
    "4. Network Analysis: Flow and congestion patterns.\n",
    "5. Scenario Comparison: Real vs augmented model performance.\n",
    "\n",
    "\n",
    "NOTE: Additional analysis will be included in time. \n",
    "\"\"\"\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Section 0 — Install / pre-checks\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Recommended environment: conda or venv with Python 3.9+ and these packages installed.\n",
    "# Python packages used in this notebook (uncomment to install in a notebook environment):\n",
    "# !pip install pandas geopandas matplotlib numpy sumolib\n",
    "\n",
    "import os, sys, subprocess, shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "try:\n",
    "    import geopandas as gpd\n",
    "except Exception:\n",
    "    gpd = None\n",
    "\n",
    "try:\n",
    "    from sumolib import net as sumonet\n",
    "    from sumolib import routes as sumoroutes\n",
    "except Exception:\n",
    "    sumonet = None\n",
    "\n",
    "# Create plots directory - replace with your own path\n",
    "plots_dir = Path('/home/adingil/test/plots')\n",
    "plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Plots will be saved to: {plots_dir.absolute()}\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Section 1 — Clone any repo and file discovery\n",
    "# ---------------------------------------------\n",
    "\n",
    "# EXAMPLE REPO PROVIDING EXPERIMENTAL BRUSSELS SCENARIOS\n",
    "\n",
    "REPO_URL = 'https://gitlab.com/traffic-sim/traffic_data_augmentation.git'\n",
    "LOCAL_DIR = Path('/home/adingil/test/repo') #replace with your own path\n",
    "if not LOCAL_DIR.exists():\n",
    "    print('Cloning repo...')\n",
    "    subprocess.run(['git', 'clone', REPO_URL, str(LOCAL_DIR)], check=True)\n",
    "else:\n",
    "    print('Repo already present at', LOCAL_DIR)\n",
    "\n",
    "# run git lfs pull if needed\n",
    "print('\\nChecking for large files...')\n",
    "subprocess.run(['git', '-C', str(LOCAL_DIR), 'lfs', 'pull'], capture_output=True)\n",
    "\n",
    "# Detect candidate paths\n",
    "scenarios_dir = LOCAL_DIR / 'scenarios'\n",
    "dataset_dir = LOCAL_DIR / 'dataset' / 'augmented_data'\n",
    "\n",
    "# Use the repo structure instead of external directories\n",
    "outputs_real_dir = LOCAL_DIR / 'real_outputs'\n",
    "outputs_augmented_dir = LOCAL_DIR / 'augmented_outputs'\n",
    "maps_dir = LOCAL_DIR / 'scenarios' / 'map'\n",
    "\n",
    "print('scenarios exists?', scenarios_dir.exists())\n",
    "print('dataset exists?', dataset_dir.exists())\n",
    "print('maps exists?', maps_dir.exists())\n",
    "print('real outputs exists?', outputs_real_dir.exists())\n",
    "print('augmented outputs exists?', outputs_augmented_dir.exists())\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Section 2 — Locate SUMO tools and visualization scripts\n",
    "# ---------------------------------------------\n",
    "\n",
    "SUMO_BIN = shutil.which('sumo') or shutil.which('sumo-gui')\n",
    "SUMO_GUI = shutil.which('sumo-gui')\n",
    "PLOT_TOOLS_DIR = os.getenv('SUMO_HOME') and Path(os.getenv('SUMO_HOME')) / 'tools' / 'visualization'\n",
    "\n",
    "print('SUMO binary:', SUMO_BIN)\n",
    "print('SUMO-GUI:', SUMO_GUI)\n",
    "print('Visualization tools dir:', PLOT_TOOLS_DIR if PLOT_TOOLS_DIR else 'SUMO_HOME not set — try to call installed scripts directly')\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Section 3 — Detect sumo network and sumo outputs in the repo\n",
    "# ---------------------------------------------\n",
    "\n",
    "net_xml = None\n",
    "if maps_dir.exists():\n",
    "    for p in maps_dir.glob('*'):\n",
    "        if p.suffix == '.xml' and 'net' in p.name:\n",
    "            net_xml = p\n",
    "            break\n",
    "print('Detected network xml:', net_xml)\n",
    "\n",
    "#Use the repo directories\n",
    "real_output_files = (list(outputs_real_dir.rglob('*edgedata.out*.xml')) + \n",
    "                list(outputs_real_dir.rglob('*detector.out*.xml')) + \n",
    "                list(outputs_real_dir.rglob('*fcd.out*.xml')) + \n",
    "                list(outputs_real_dir.rglob('*tripinfo.out*.xml')) + \n",
    "                list(outputs_real_dir.rglob('*summary.out*.xml')) + \n",
    "                list(outputs_real_dir.rglob('*vehroute.out*.xml')))\n",
    "print('Found real SUMO output candidates:', [p.name for p in real_output_files[:10]])\n",
    "print('Total real output files:', len(real_output_files))\n",
    "\n",
    "augmented_output_files = (list(outputs_augmented_dir.rglob('*edgedata.out*.xml')) + \n",
    "                list(outputs_augmented_dir.rglob('*detector.out*.xml')) + \n",
    "                list(outputs_augmented_dir.rglob('*fcd*.xml')) + \n",
    "                list(outputs_augmented_dir.rglob('*tripinfo.out*.xml')) + \n",
    "                list(outputs_augmented_dir.rglob('*summary.out*.xml')) + \n",
    "                list(outputs_augmented_dir.rglob('*vehroute.out*.xml')))\n",
    "print('Found augmented SUMO output candidates:', [p.name for p in augmented_output_files[:10]])\n",
    "print('Total augmented output files:', len(augmented_output_files))\n",
    "\n",
    "# If no files found in expected locations, try alternative locations\n",
    "if len(real_output_files) == 0:\n",
    "    print(\"No files found in real_outputs directory, trying alternative locations...\")\n",
    "    # Try to find any output files in the entire repo\n",
    "    alternative_real_files = list(LOCAL_DIR.rglob('*edgedata*.xml')) + list(LOCAL_DIR.rglob('*detector*.xml'))\n",
    "    print(f\"Found alternative files: {[f.name for f in alternative_real_files[:5]]}\")\n",
    "    real_output_files = alternative_real_files\n",
    "\n",
    "if len(augmented_output_files) == 0:\n",
    "    print(\"No files found in augmented_outputs directory, trying alternative locations...\")\n",
    "    alternative_aug_files = list(LOCAL_DIR.rglob('*tripinfo*.xml')) + list(LOCAL_DIR.rglob('*summary*.xml'))\n",
    "    print(f\"Found alternative files: {[f.name for f in alternative_aug_files[:5]]}\")\n",
    "    augmented_output_files = alternative_aug_files\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Section 4 — SUMO visualization PART1\n",
    "# ---------------------------------------------\n",
    "\n",
    "# For generating a series of 2D plots comparing two selected output attributes from one or more XML output files, grouped by a third attribute when needed.\n",
    "# Simulation models are functioning correctly when the vehicle movement metrics show rational patterns. This section allows you to control the arrival, departure, running, waiting, halting, and some other patterns of the vehicles to ensure this.\n",
    "# Detectors are functional if occupancy and speed parameters show a rational variation. This section allows you to pick important loop detectors and investigate their operational metrics during simulation time.\n",
    "\n",
    "#Extract:\n",
    "\n",
    "def extract_date_from_path(file_path):\n",
    "    \"\"\"Extract date from file path like .../real_outputs/2024-03-25/3000/idExp0/calibration_iter9/...\"\"\"\n",
    "    try:\n",
    "        parts = file_path.parts\n",
    "        # Look for the date pattern in the path\n",
    "        for i, part in enumerate(parts):\n",
    "            if '-' in part and len(part) == 10:  # Date pattern: YYYY-MM-DD\n",
    "                # Check if it's actually a date\n",
    "                year, month, day = part.split('-')\n",
    "                if year.isdigit() and month.isdigit() and day.isdigit():\n",
    "                    return part\n",
    "        # If no date found in standard location, try to find any date-like pattern\n",
    "        for part in parts:\n",
    "            if '-' in part and len(part) == 10:\n",
    "                year, month, day = part.split('-')\n",
    "                if year.isdigit() and month.isdigit() and day.isdigit():\n",
    "                    return part\n",
    "        return \"unknown_date\"\n",
    "    except:\n",
    "        return \"unknown_date\"\n",
    "        \n",
    "# Visualization basement:\n",
    "\n",
    "def run_plot_xml_attributes(xmlfile, xattr='begin', yattr='nVehEntered', idattr='id', out='plot.png', extra_args=None):\n",
    "    \"\"\"Call SUMO's plotXMLAttributes.py script if available in PATH or SUMO_HOME/tools/visualization.\"\"\"\n",
    "    # Check if input file exists\n",
    "    if not xmlfile.exists():\n",
    "        print(f\"Input file {xmlfile} not found. Skipping.\")\n",
    "        return None\n",
    "        \n",
    "    script = shutil.which('plotXMLAttributes.py')\n",
    "    if not script and PLOT_TOOLS_DIR:\n",
    "        candidate = PLOT_TOOLS_DIR / 'plotXMLAttributes.py'\n",
    "        if candidate.exists():\n",
    "            script = str(candidate)\n",
    "    if not script:\n",
    "        print('plotXMLAttributes.py not found. Please set SUMO_HOME or install SUMO tools. Falling back to Python plotting for', xmlfile)\n",
    "        return None\n",
    "        \n",
    "    cmd = [script, '-x', xattr, '-y', yattr, '-i', idattr, str(xmlfile), '-o', out]\n",
    "    if extra_args:\n",
    "        cmd += extra_args\n",
    "    print('Running:', ' '.join(cmd))\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)\n",
    "        if result.returncode != 0:\n",
    "            print(f\"Error running plotXMLAttributes: {result.stderr}\")\n",
    "            return None\n",
    "        print(f\"Successfully created plot: {out}\")\n",
    "        return out\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"Plotting timed out for {xmlfile}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error plotting {xmlfile}: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Section 4 - Generating Operational Plots\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Example-1 General overview plot of vehicle dynamics over time, observing running & halting vehicles evolution over simulation time:\n",
    "\n",
    "if len(real_output_files) > 0:\n",
    "    for f in real_output_files:\n",
    "        if 'summary' in f.name:\n",
    "            date_str = extract_date_from_path(f)\n",
    "            print(f'Will attempt to plot Data from {f.name} (Date: {date_str})')\n",
    "            output_path = plots_dir / f'veh_runninghalting_{date_str}_{f.stem}.png'\n",
    "            run_plot_xml_attributes(\n",
    "                f,\n",
    "                xattr='time',\n",
    "                yattr='running,halting',\n",
    "                idattr='id',\n",
    "                out=str(output_path),\n",
    "                extra_args=[\n",
    "                    '--legend',\n",
    "                    '--xlabel', 'Time [s]',\n",
    "                    '--ylabel', 'Running & Halting Vehicles [s]',\n",
    "                    '--title', 'Running & Halting Vehicles over Time',\n",
    "                    '--titlesize', '16'\n",
    "                ]\n",
    "            )\n",
    "\n",
    "# Example 1.1 General overview plot of vehicle dynamics over time, observing running & waiting vehicles evolution during simulations.\n",
    "\n",
    "if len(real_output_files) > 0:\n",
    "    for f in real_output_files:\n",
    "        if 'summary' in f.name:\n",
    "            date_str = extract_date_from_path(f)\n",
    "            print(f'Will attempt to plot Data from {f.name} (Date: {date_str})')\n",
    "            output_path = plots_dir / f'veh_runningwaiting_{date_str}_{f.stem}.png'\n",
    "            run_plot_xml_attributes(\n",
    "                f,\n",
    "                xattr='time',\n",
    "                yattr='running,waiting',\n",
    "                idattr='id',\n",
    "                out=str(output_path),\n",
    "                extra_args=[\n",
    "                    '--legend',\n",
    "                    '--xlabel', 'Time [s]',\n",
    "                    '--ylabel', 'Running & Waiting Vehicles [s]',\n",
    "                    '--title', 'Running & Waiting Vehicles over Time',\n",
    "                    '--titlesize', '16'\n",
    "                ]\n",
    "            )\n",
    "\n",
    "# Example 1.2 General overview plot of vehicle dynamics over time, observing running & teleported vehicles evolution during simulations.\n",
    "\n",
    "if len(real_output_files) > 0:\n",
    "    for f in real_output_files:\n",
    "        if 'summary' in f.name:\n",
    "            date_str = extract_date_from_path(f)\n",
    "            print(f'Will attempt to plot Data from {f.name} (Date: {date_str})')\n",
    "            output_path = plots_dir / f'veh_runningteleport_{date_str}_{f.stem}.png'\n",
    "            run_plot_xml_attributes(\n",
    "                f,\n",
    "                xattr='time',\n",
    "                yattr='running,teleports',\n",
    "                idattr='id',\n",
    "                out=str(output_path),\n",
    "                extra_args=[\n",
    "                    '--legend',\n",
    "                    '--xlabel', 'Time [s]',\n",
    "                    '--ylabel', 'Running & Teleported Vehicles [s]',\n",
    "                    '--title', 'Running & Teleported Vehicles over Time',\n",
    "                    '--titlesize', '16'\n",
    "                ]\n",
    "            )\n",
    "\n",
    "# Example 1.3 General overview plot of vehicle dynamics over time, observing mean travel time & mean waiting time evolution during simulations.\n",
    "\n",
    "if len(real_output_files) > 0:\n",
    "    for f in real_output_files:\n",
    "        if 'summary' in f.name:\n",
    "            date_str = extract_date_from_path(f)\n",
    "            print(f'Will attempt to plot Data from {f.name} (Date: {date_str})')\n",
    "            output_path = plots_dir / f'veh_meanTTWT_{date_str}_{f.stem}.png'\n",
    "            run_plot_xml_attributes(\n",
    "                f,\n",
    "                xattr='time',\n",
    "                yattr='meanTravelTime,meanWaitingTime',\n",
    "                idattr='id',\n",
    "                out=str(output_path),\n",
    "                extra_args=[\n",
    "                    '--legend',\n",
    "                    '--xlabel', 'Time [s]',\n",
    "                    '--ylabel', 'Travel Time & Waiting Time [s]',\n",
    "                    '--title', 'Travel and Waiting Time Evolution of Vehicles',\n",
    "                    '--titlesize', '16'\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    \n",
    "# Example-2 General overview plot of departure and arrival timing during day, investigating departure-arrival evolution over simulation time:\n",
    "\n",
    "if len(real_output_files) > 0:\n",
    "    for f in real_output_files:\n",
    "        if 'vehroute' in f.name:\n",
    "            date_str = extract_date_from_path(f)\n",
    "            print(f'Will attempt to plot Data from {f.name} (Date: {date_str})')\n",
    "            output_path = plots_dir / f'depart_arrival_{date_str}_{f.stem}.png'\n",
    "            run_plot_xml_attributes(\n",
    "                f,\n",
    "                xattr='depart',\n",
    "                yattr='arrival',\n",
    "                idattr='id',\n",
    "                out=str(output_path),\n",
    "                extra_args=[\n",
    "                    '--scatterplot',\n",
    "                    '--xlabel', 'Depart time [s]',\n",
    "                    '--ylabel', 'Arrival time [s]',\n",
    "                    '--title', 'Departure time over arrival time',\n",
    "                    '--titlesize', '16'\n",
    "                ]\n",
    "            )\n",
    "\n",
    "# Example-3 General overview plot of departure delay, investigating delays over simulation time:\n",
    "\n",
    "if len(real_output_files) > 0:\n",
    "    for f in real_output_files:\n",
    "        if 'tripinfo' in f.name:\n",
    "            date_str = extract_date_from_path(f)\n",
    "            print(f'Will attempt to plot Data from {f.name} (Date: {date_str})')\n",
    "            output_path = plots_dir / f'depart_{date_str}_{f.stem}.png'\n",
    "            run_plot_xml_attributes(\n",
    "                f,\n",
    "                xattr='depart',\n",
    "                yattr='departDelay',\n",
    "                idattr='id',\n",
    "                out=str(output_path),\n",
    "                extra_args=[\n",
    "                    '--scatterplot',\n",
    "                    '--xlabel', 'Depart time [s]',\n",
    "                    '--ylabel', 'Depart delay [s]',\n",
    "                    '--ylim', '0,1800',\n",
    "                    '--xticks', '0,86400,7200,10',\n",
    "                    '--yticks', '0,1800,100,10', \n",
    "                    '--xgrid',\n",
    "                    '--ygrid',\n",
    "                    '--title', 'Depart delay over depart time',\n",
    "                    '--titlesize', '16'\n",
    "                ]\n",
    "            )\n",
    "\n",
    "# Example-4 General overview plot of detector occupancy variations over time, investigating important detectors’ patterns:\n",
    "if len(real_output_files) > 0:\n",
    "    for f in real_output_files:\n",
    "        if 'detector.out' in f.name:\n",
    "            date_str = extract_date_from_path(f)\n",
    "            print(f'Will attempt to plot Data from {f.name} (Date: {date_str})')\n",
    "            output_path = plots_dir / f'detector_occupancy_{date_str}_{f.stem}.png'\n",
    "            run_plot_xml_attributes(\n",
    "                f,\n",
    "                xattr='begin',\n",
    "                yattr='occupancy',\n",
    "                idattr='id',\n",
    "                out=str(output_path),\n",
    "                extra_args=[\n",
    "                    '--legend',\n",
    "                    '--filter-ids', 'BXLBXL034144F1_0,BXLJET127338F1_0,BXLUCC034671F1_0,BXLUCC127337F1_0,BXLJET139438B1_0', #change with detector IDs you would like to investigate\n",
    "                    '--xlabel', 'Time [s]',\n",
    "                    '--ylabel', 'Occupancy',\n",
    "                    '--ylim', '0,50',\n",
    "                    '--xticks', '0,86400,7200,10',\n",
    "                    '--yticks', '0,50,5,10',\n",
    "                    '--xgrid',\n",
    "                    '--ygrid',\n",
    "                    '--title', 'Detector Occupancy',\n",
    "                    '--titlesize', '16'\n",
    "                ]\n",
    "            )\n",
    "\n",
    "# Example-5 General overview plot of vehicle speed variation over detectors, investigating important detectors’ pattern:\n",
    "if len(real_output_files) > 0:\n",
    "    for f in real_output_files:\n",
    "        if 'detector.out' in f.name:\n",
    "            date_str = extract_date_from_path(f)\n",
    "            print(f'Will attempt to plot Data from {f.name} (Date: {date_str})')\n",
    "            output_path = plots_dir / f'detector_speed_{date_str}_{f.stem}.png'\n",
    "            run_plot_xml_attributes(\n",
    "                f,\n",
    "                xattr='begin',\n",
    "                yattr='speed',\n",
    "                idattr='id',\n",
    "                out=str(output_path),\n",
    "                extra_args=[\n",
    "                    '--legend',\n",
    "                    '--filter-ids', 'BXLBXL034144F1_0,BXLJET127338F1_0,BXLUCC034671F1_0,BXLUCC127337F1_0,BXLJET139438B1_0', #change with detector IDs you would like to investigate\n",
    "                    '--xlabel', 'Time [s]',\n",
    "                    '--ylabel', 'Speed',  #m/s\n",
    "                    '--ylim', '0,16',\n",
    "                    '--xticks', '0,86400,7200,10',\n",
    "                    '--yticks', '0,16,2,10',\n",
    "                    '--xgrid',\n",
    "                    '--ygrid',\n",
    "                    '--xgrid',                    \n",
    "                    '--title', 'Speed over Detectors',\n",
    "                    '--titlesize', '16',\n",
    "                ]\n",
    "            )\n",
    "else:\n",
    "    print(\"No real output files found for Section 4 analysis\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Section 5 — SUMO Visualization PART2\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Visualize traffic & simulation outputs\n",
    "# Urban traffic is rational if its patterns reflect real-life conditions. This section allows you to investigate important traffic metrics during simulation time.\n",
    "# For generating a network visualization where the color and width of the edges are dynamically styled based on predefined edge attributes. \n",
    "\n",
    "# This section also provides all necessary performance metrics for each edge in the road network for every scenario in CSV format for users and outputs descriptive stats of these metrics (min, max, mean, median, etc.) for each simulation, as well as global statistics to help explore thresholds and critical values for better visualization.\n",
    "\n",
    "# Pop up some descriptive stats (min, max, mean, median, etc.) of important traffic values from the simulation outputs to explore the results.\n",
    " \n",
    "\n",
    "def analyze_edge_statistics(file_path, global_stats=None):\n",
    "    \"\"\"Analyze max, min, mean, median of edge attributes.\"\"\"\n",
    "    if not file_path.exists():\n",
    "        print(f\"Edge data file {file_path} not found. Skipping statistics.\")\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        tree = ET.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        indicators = [\n",
    "            \"occupancy\", \"timeLoss\", \"density\", \"waitingTime\", \"traveltime\", \"speed\", \"speedRelative\",\n",
    "            \"overlapTraveltime\", \"departed\", \"arrived\", \"entered\", \"teleported\", \"sampledSeconds\"\n",
    "        ]\n",
    "\n",
    "        stats = {\n",
    "            key: {\n",
    "                'max': {'id': None, 'value': float('-inf'), 'file': None, 'date': None},  \n",
    "                'min': {'id': None, 'value': float('inf'), 'file': None, 'date': None},  \n",
    "                'sum': 0.0,\n",
    "                'count': 0,\n",
    "                'values': []\n",
    "            } for key in indicators\n",
    "        }\n",
    "\n",
    "        # Extract date once for this file\n",
    "        date_str = extract_date_from_path(file_path)\n",
    "\n",
    "        for edge in root.iter('edge'):\n",
    "            edge_id = edge.attrib['id']\n",
    "            for indicator in indicators:\n",
    "                value_str = edge.attrib.get(indicator)\n",
    "                if value_str is not None:\n",
    "                    try:\n",
    "                        value = float(value_str)\n",
    "                        # max\n",
    "                        if value > stats[indicator]['max']['value']:\n",
    "                            stats[indicator]['max'] = {\n",
    "                                'id': edge_id, \n",
    "                                'value': value, \n",
    "                                'file': file_path.name,\n",
    "                                'date': date_str  \n",
    "                            }\n",
    "                        # min\n",
    "                        if value < stats[indicator]['min']['value']:\n",
    "                            stats[indicator]['min'] = {\n",
    "                                'id': edge_id, \n",
    "                                'value': value, \n",
    "                                'file': file_path.name,\n",
    "                                'date': date_str  \n",
    "                            }\n",
    "                        stats[indicator]['sum'] += value\n",
    "                        stats[indicator]['count'] += 1\n",
    "                        stats[indicator]['values'].append(value)\n",
    "                        \n",
    "                        # global statistics if provided\n",
    "                        if global_stats is not None:\n",
    "                            if indicator not in global_stats:\n",
    "                                global_stats[indicator] = {\n",
    "                                    'global_max': {'id': None, 'value': float('-inf'), 'file': None, 'date': None},\n",
    "                                    'global_min': {'id': None, 'value': float('inf'), 'file': None, 'date': None},\n",
    "                                    'global_sum': 0.0,\n",
    "                                    'global_count': 0,\n",
    "                                    'global_values': []\n",
    "                                }\n",
    "                            \n",
    "                            # global max\n",
    "                            if value > global_stats[indicator]['global_max']['value']:\n",
    "                                global_stats[indicator]['global_max'] = {\n",
    "                                    'id': edge_id, \n",
    "                                    'value': value, \n",
    "                                    'file': file_path.name,\n",
    "                                    'date': date_str  \n",
    "                                }\n",
    "                            # global min\n",
    "                            if value < global_stats[indicator]['global_min']['value']:\n",
    "                                global_stats[indicator]['global_min'] = {\n",
    "                                    'id': edge_id, \n",
    "                                    'value': value, \n",
    "                                    'file': file_path.name,\n",
    "                                    'date': date_str  \n",
    "                                }\n",
    "                            global_stats[indicator]['global_sum'] += value\n",
    "                            global_stats[indicator]['global_count'] += 1\n",
    "                            global_stats[indicator]['global_values'].append(value)\n",
    "                            \n",
    "                    except (ValueError, TypeError):\n",
    "                        continue\n",
    "\n",
    "        # Print results for this file\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Edge Statistics for {file_path.name} (Date: {date_str})\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        for indicator, data in stats.items():\n",
    "            if data['count'] > 0:\n",
    "                avg = data['sum'] / data['count']\n",
    "                sorted_values = sorted(data['values'])\n",
    "                n = len(sorted_values)\n",
    "                if n % 2 == 0:\n",
    "                    median = (sorted_values[n//2 - 1] + sorted_values[n//2]) / 2\n",
    "                else:\n",
    "                    median = sorted_values[n//2]\n",
    "                \n",
    "                print(f\"\\nIndicator: {indicator}\")\n",
    "                print(f\"  Count:  {data['count']} edges\")\n",
    "                print(f\"  Max:    {data['max']['value']:.6f} on edge {data['max']['id']} (Date: {data['max']['date']})\")  # Show date\n",
    "                print(f\"  Min:    {data['min']['value']:.6f} on edge {data['min']['id']} (Date: {data['min']['date']})\")  # Show date\n",
    "                print(f\"  Mean:   {avg:.6f}\")\n",
    "                print(f\"  Median: {median:.6f}\")\n",
    "            else:\n",
    "                print(f\"\\nIndicator: {indicator} - No data found\")\n",
    "                \n",
    "        return stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing edge statistics for {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def print_global_statistics(global_stats):\n",
    "    \"\"\"Print global statistics across all files.\"\"\"\n",
    "    if not global_stats:\n",
    "        print(\"No global statistics to display.\")\n",
    "        return\n",
    "        \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"GLOBAL STATISTICS (Across All Files)\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for indicator, data in global_stats.items():\n",
    "        if data['global_count'] > 0:\n",
    "            global_avg = data['global_sum'] / data['global_count']\n",
    "            # Calculate global median\n",
    "            sorted_global_values = sorted(data['global_values'])\n",
    "            n_global = len(sorted_global_values)\n",
    "            if n_global % 2 == 0:\n",
    "                global_median = (sorted_global_values[n_global//2 - 1] + sorted_global_values[n_global//2]) / 2\n",
    "            else:\n",
    "                global_median = sorted_global_values[n_global//2]\n",
    "            \n",
    "            print(f\"\\nIndicator: {indicator}\")\n",
    "            print(f\"  Global Count:  {data['global_count']} edges across all files\")\n",
    "            print(f\"  Global Max:    {data['global_max']['value']:.6f} on edge {data['global_max']['id']} (File: {data['global_max']['file']}, Date: {data['global_max']['date']})\")\n",
    "            print(f\"  Global Min:    {data['global_min']['value']:.6f} on edge {data['global_min']['id']} (File: {data['global_min']['file']}, Date: {data['global_min']['date']})\")\n",
    "            print(f\"  Global Mean:   {global_avg:.6f}\")\n",
    "            print(f\"  Global Median: {global_median:.6f}\")\n",
    "        else:\n",
    "            print(f\"\\nIndicator: {indicator} - No global data found\")\n",
    "\n",
    "def save_global_statistics_to_csv(global_stats, file_path):\n",
    "    \"\"\"Save global statistics to a CSV file.\"\"\"\n",
    "    try:\n",
    "        # Prepare data for CSV\n",
    "        csv_data = []\n",
    "        for indicator, data in global_stats.items():\n",
    "            if data['global_count'] > 0:\n",
    "                global_avg = data['global_sum'] / data['global_count']\n",
    "                # Calculate global median\n",
    "                sorted_global_values = sorted(data['global_values'])\n",
    "                n_global = len(sorted_global_values)\n",
    "                if n_global % 2 == 0:\n",
    "                    global_median = (sorted_global_values[n_global//2 - 1] + sorted_global_values[n_global//2]) / 2\n",
    "                else:\n",
    "                    global_median = sorted_global_values[n_global//2]\n",
    "                \n",
    "                csv_data.append({\n",
    "                    'Indicator': indicator,\n",
    "                    'Global_Count': data['global_count'],\n",
    "                    'Global_Max_Value': data['global_max']['value'],\n",
    "                    'Global_Max_Edge': data['global_max']['id'],\n",
    "                    'Global_Max_File': data['global_max']['file'],\n",
    "                    'Global_Max_Date': data['global_max']['date'], \n",
    "                    'Global_Min_Value': data['global_min']['value'],\n",
    "                    'Global_Min_Edge': data['global_min']['id'],\n",
    "                    'Global_Min_File': data['global_min']['file'],\n",
    "                    'Global_Min_Date': data['global_min']['date'], \n",
    "                    'Global_Mean': global_avg,\n",
    "                    'Global_Median': global_median\n",
    "                })\n",
    "        \n",
    "        if csv_data:\n",
    "            df = pd.DataFrame(csv_data)\n",
    "            df.to_csv(file_path, index=False)\n",
    "            print(f\"Global statistics saved to CSV: {file_path}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"No global statistics data to save.\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving global statistics to CSV: {e}\")\n",
    "        return False\n",
    "\n",
    "def save_individual_statistics_to_csv(individual_stats, plots_dir):\n",
    "    \"\"\"Save individual file statistics to a CSV file.\"\"\"\n",
    "    try:\n",
    "        # Prepare data for CSV\n",
    "        csv_data = []\n",
    "        \n",
    "        for file_path, stats in individual_stats.items():\n",
    "            if stats is None:\n",
    "                continue\n",
    "                \n",
    "            date_str = extract_date_from_path(file_path)\n",
    "            \n",
    "            for indicator, data in stats.items():\n",
    "                if data['count'] > 0:\n",
    "                    avg = data['sum'] / data['count']\n",
    "                    sorted_values = sorted(data['values'])\n",
    "                    n = len(sorted_values)\n",
    "                    if n % 2 == 0:\n",
    "                        median = (sorted_values[n//2 - 1] + sorted_values[n//2]) / 2\n",
    "                    else:\n",
    "                        median = sorted_values[n//2]\n",
    "                    \n",
    "                    csv_data.append({\n",
    "                        'File': file_path.name,\n",
    "                        'Date': date_str,\n",
    "                        'Indicator': indicator,\n",
    "                        'Count': data['count'],\n",
    "                        'Max_Value': data['max']['value'],\n",
    "                        'Max_Edge': data['max']['id'],\n",
    "                        'Min_Value': data['min']['value'],\n",
    "                        'Min_Edge': data['min']['id'],\n",
    "                        'Mean': avg,\n",
    "                        'Median': median\n",
    "                    })\n",
    "        \n",
    "        if csv_data:\n",
    "            df = pd.DataFrame(csv_data)\n",
    "            csv_file_path = plots_dir / 'individual_statistics.csv'\n",
    "            df.to_csv(csv_file_path, index=False)\n",
    "            print(f\"Individual statistics saved to CSV: {csv_file_path}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"No individual statistics data to save.\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving individual statistics to CSV: {e}\")\n",
    "        return False\n",
    "\n",
    "def save_detailed_edge_data_to_csv(file_path, plots_dir):\n",
    "    \"\"\"Save detailed edge-level data to CSV for further analysis.\"\"\"\n",
    "    if not file_path.exists():\n",
    "        print(f\"File {file_path} not found. Skipping detailed edge data export.\")\n",
    "        return False\n",
    "        \n",
    "    try:\n",
    "        # Extract date for unique filename\n",
    "        date_str = extract_date_from_path(file_path)\n",
    "        \n",
    "        # Load and parse the XML file\n",
    "        tree = ET.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # Indicators to extract\n",
    "        indicators = [\n",
    "            \"occupancy\", \"timeLoss\", \"density\", \"waitingTime\", \"traveltime\", \"speed\", \"speedRelative\",\n",
    "            \"overlapTraveltime\", \"departed\", \"arrived\", \"entered\", \"teleported\", \"sampledSeconds\"\n",
    "        ]\n",
    "\n",
    "        # Collect all edge data\n",
    "        edge_data = []\n",
    "        for edge in root.iter('edge'):\n",
    "            edge_info = {'Edge_ID': edge.attrib['id']}\n",
    "            for indicator in indicators:\n",
    "                value_str = edge.attrib.get(indicator)\n",
    "                if value_str is not None:\n",
    "                    try:\n",
    "                        edge_info[indicator] = float(value_str)\n",
    "                    except (ValueError, TypeError):\n",
    "                        edge_info[indicator] = None\n",
    "                else:\n",
    "                    edge_info[indicator] = None\n",
    "            edge_data.append(edge_info)\n",
    "        \n",
    "        if edge_data:\n",
    "            df = pd.DataFrame(edge_data)\n",
    "            csv_filename = f\"detailed_edges_{date_str}_{file_path.stem}.csv\"\n",
    "            csv_file_path = plots_dir / csv_filename\n",
    "            df.to_csv(csv_file_path, index=False)\n",
    "            print(f\"Detailed edge data saved to CSV: {csv_file_path}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"No edge data found in {file_path.name}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving detailed edge data for {file_path} to CSV: {e}\")\n",
    "        return False\n",
    "\n",
    "# Visualization basement:\n",
    "\n",
    "def run_plot_net_dump(netfile, edgefile, measures, out, extra_args=None):\n",
    "    \"\"\"Call SUMO's plot_net_dump.py with given parameters.\"\"\"\n",
    "    # Check if input files exist\n",
    "    if not netfile or not netfile.exists():\n",
    "        print(f\"Network file {netfile} not found. Skipping.\")\n",
    "        return None\n",
    "    if not edgefile.exists():\n",
    "        print(f\"Edge data file {edgefile} not found. Skipping.\")\n",
    "        return None\n",
    "        \n",
    "    script = shutil.which('plot_net_dump.py')\n",
    "    if not script and PLOT_TOOLS_DIR:\n",
    "        candidate = PLOT_TOOLS_DIR / 'plot_net_dump.py'\n",
    "        if candidate.exists():\n",
    "            script = str(candidate)\n",
    "    if not script:\n",
    "        print('plot_net_dump.py not found. Please set SUMO_HOME or install SUMO tools.')\n",
    "        return None\n",
    "    \n",
    "    cmd = [script, \"-v\", \"-n\", str(netfile), \"--measures\", measures, \"-i\", f\"{edgefile},{edgefile}\", \"--output\", out]\n",
    "    if extra_args:\n",
    "        cmd += extra_args\n",
    "    print(\"Running:\", \" \".join(cmd))\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)  # Longer timeout for network plots\n",
    "        if result.returncode != 0:\n",
    "            print(f\"Error running plot_net_dump: {result.stderr}\")\n",
    "            return None\n",
    "        return out\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"Network plotting timed out for {edgefile}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error plotting network for {edgefile}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Analyzing Road Statistics and Generating Network Visualizations\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Section 5 - Analyzing Road Statistics and Generating Network Visualizations\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize global statistics dictionary\n",
    "global_stats = {}\n",
    "individual_stats = {}  # Dictionary to store individual file stats\n",
    "\n",
    "for f in real_output_files:\n",
    "    if 'edgedata.out' in f.name:\n",
    "        file_stats = analyze_edge_statistics(f, global_stats)\n",
    "        individual_stats[f] = file_stats  # Store individual file stats\n",
    "        \n",
    "        # Save detailed edge data for each file\n",
    "        save_detailed_edge_data_to_csv(f, plots_dir)\n",
    "\n",
    "# Print global statistics after processing all files\n",
    "print_global_statistics(global_stats)\n",
    "\n",
    "# Save statistics to CSV files\n",
    "if global_stats:\n",
    "    # Save global statistics\n",
    "    global_csv_path = plots_dir / 'global_statistics.csv'\n",
    "    save_global_statistics_to_csv(global_stats, global_csv_path)\n",
    "    \n",
    "    # Save individual file statistics\n",
    "    save_individual_statistics_to_csv(individual_stats, plots_dir)\n",
    "\n",
    "\n",
    "# To analyze edge indicators by identifying locations where their values peak or trough - observing their distribution across the transport system\n",
    "\n",
    "for f in real_output_files:\n",
    "    if 'edgedata.out' in f.name:\n",
    "        date_str = extract_date_from_path(f)\n",
    "        print(f'Generating network plots for {f.name} (Date: {date_str})')\n",
    "        \n",
    "# Example-1: A coloured city map providing Edge Usage Analysis - The number of vehicles that used each road during the simulation, ranked from the busiest to the least utilized streets. This data can be validated against real-world observations from sources like TomTom and Google to assess the model's accuracy.\n",
    "        \n",
    "        output_path = plots_dir / f'edgeusage_{date_str}_{f.stem}.png'\n",
    "        run_plot_net_dump(\n",
    "            net_xml,\n",
    "            f,\n",
    "            \"entered,entered\",\n",
    "            str(output_path),\n",
    "            extra_args=[\n",
    "                \"--xlim\", \"900,16000\",\n",
    "                \"--ylim\", \"4500,16000\",\n",
    "                \"--xticks\", \"1000,16000,2500,5\",\n",
    "                \"--yticks\", \"2000,16000,2500,5\",\n",
    "                \"--xlabel\", \"[m]\",\n",
    "                \"--ylabel\", \"[m]\",\n",
    "                \"--default-width\", \"0.3\",\n",
    "                \"--default-color\", \"#606060\",\n",
    "                \"--min-color-value\", \"0\",\n",
    "                \"--max-color-value\", \"2000\",\n",
    "                \"--max-width-value\", \"2000\",\n",
    "                \"--max-width\", \"1.3\",\n",
    "                \"--min-width\", \"0.3\",\n",
    "                \"--colormap\", \"jet\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "# Example-2: A coloured city map providing Overall Time Loss Analysis - The total delay in seconds (summed per road) caused by vehicles traveling slower than their desired speed. This is a primary method for detecting congestion and deadlocks; high values indicate a problematic model or network.\n",
    "\n",
    "        output_path = plots_dir / f'timeloss_{date_str}_{f.stem}.png'\n",
    "        run_plot_net_dump(\n",
    "            net_xml,\n",
    "            f,\n",
    "            \"timeLoss,timeLoss\",\n",
    "            str(output_path),\n",
    "            extra_args=[\n",
    "                \"--xlim\", \"900,16000\",\n",
    "                \"--ylim\", \"4500,16000\",\n",
    "                \"--xticks\", \"1000,16000,2500,5\",\n",
    "                \"--yticks\", \"2000,16000,2500,5\",\n",
    "                \"--xlabel\", \"[m]\",\n",
    "                \"--ylabel\", \"[m]\",\n",
    "                \"--default-width\", \"0.3\",\n",
    "                \"--default-color\", \"#606060\",\n",
    "                \"--max-color-value\", \"1800\", # half hour\n",
    "                \"--max-width-value\", \"1800\", # half hour\n",
    "                \"--max-width\", \"1.3\",\n",
    "                \"--min-width\", \"0.3\",\n",
    "                \"--colormap\", \"jet\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "# Example-3: A coloured city map providing Waiting Time Analysis - The total number of seconds (aggregated for each road) that vehicles spent halted (speed < speed threshold). This analysis helps identify intersections and road segments where traffic flow is inefficient, providing key insights into the model's performance.\n",
    "\n",
    "\n",
    "        output_path = plots_dir / f'waitingtime_{date_str}_{f.stem}.png'\n",
    "        run_plot_net_dump(\n",
    "            net_xml,\n",
    "            f,\n",
    "            \"waitingTime,waitingTime\",\n",
    "            str(output_path),\n",
    "            extra_args=[\n",
    "                \"--xlim\", \"900,16000\",\n",
    "                \"--ylim\", \"4500,16000\",\n",
    "                \"--xticks\", \"1000,16000,2500,5\",\n",
    "                \"--yticks\", \"2000,16000,2500,5\",\n",
    "                \"--xlabel\", \"[m]\",\n",
    "                \"--ylabel\", \"[m]\",\n",
    "                \"--default-width\", \"0.3\",\n",
    "                \"--default-color\", \"#606060\",\n",
    "                \"--min-color-value\", \"0\",\n",
    "                \"--max-color-value\", \"900\", # 15 min\n",
    "                \"--max-width-value\", \"900\", # 15 min\n",
    "                \"--max-width\", \"1.3\",\n",
    "                \"--min-width\", \"0.3\",\n",
    "                \"--colormap\", \"jet\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "# Example-4: Speed analysis - The mean speed (aggregated) on the roads during simulation.\n",
    "# Better understand the functionality of the running model\n",
    "\n",
    "        output_path = plots_dir / f'speed_{date_str}_{f.stem}.png'\n",
    "        run_plot_net_dump(\n",
    "            net_xml,\n",
    "            f,\n",
    "            \"speed,speed\", #m/s\n",
    "            str(output_path),\n",
    "            extra_args=[\n",
    "                \"--xlim\", \"900,16000\",\n",
    "                \"--ylim\", \"4500,16000\",\n",
    "                \"--xticks\", \"1000,16000,2500,5\",\n",
    "                \"--yticks\", \"2000,16000,2500,5\",\n",
    "                \"--xlabel\", \"[m]\",\n",
    "                \"--ylabel\", \"[m]\",\n",
    "                \"--default-width\", \"0.3\",\n",
    "                \"--default-color\", \"#606060\",\n",
    "                \"--min-color-value\", \"8\",\n",
    "                \"--min-width-value\", \"8\",\n",
    "                \"--max-color-value\", \"10\",\n",
    "                \"--max-width-value\", \"10\",\n",
    "                \"--max-width\", \"1.3\",\n",
    "                \"--min-width\", \"0.3\",\n",
    "                \"--colormap\", \"jet\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "# Example-5: A coloured city map providing Relative Speed Analysis - This calculates the ratio between the average simulated speed and the legal speed limit on each road. A ratio significantly below 1.0 indicates congestion, providing key insight into the model's functionality and performance.\n",
    "\n",
    "        output_path = plots_dir / f'speedRelative_{date_str}_{f.stem}.png'\n",
    "        run_plot_net_dump(\n",
    "            net_xml,\n",
    "            f,\n",
    "            \"speed,speed\",\n",
    "            str(output_path),\n",
    "            extra_args=[\n",
    "                \"--xlim\", \"900,16000\",\n",
    "                \"--ylim\", \"4500,16000\",\n",
    "                \"--xticks\", \"1000,16000,2500,5\",\n",
    "                \"--yticks\", \"2000,16000,2500,5\",\n",
    "                \"--xlabel\", \"[m]\",\n",
    "                \"--ylabel\", \"[m]\",\n",
    "                \"--default-width\", \"0.3\",\n",
    "                \"--default-color\", \"#606060\",\n",
    "                \"--min-color-value\", \"0.9\",\n",
    "                \"--min-width-value\", \"0.9\",                \n",
    "                \"--max-color-value\", \"1\",\n",
    "                \"--max-width-value\", \"1\",\n",
    "                \"--max-width\", \"1.3\",\n",
    "                \"--min-width\", \"0.3\",\n",
    "                \"--colormap\", \"jet\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "# Example-6: Teleportation analysis - number of vehicles teleported on roads during simulation\n",
    "# To understand realism of simulation environment, teleportation is not desired.\n",
    "\n",
    "        output_path = plots_dir / f'teleported_{date_str}_{f.stem}.png'\n",
    "        run_plot_net_dump(\n",
    "            net_xml,\n",
    "            f,\n",
    "            \"speed,speed\",\n",
    "            str(output_path),\n",
    "            extra_args=[\n",
    "                \"--xlim\", \"900,16000\",\n",
    "                \"--ylim\", \"4500,16000\",\n",
    "                \"--xticks\", \"1000,16000,2500,5\",\n",
    "                \"--yticks\", \"2000,16000,2500,5\",\n",
    "                \"--xlabel\", \"[m]\",\n",
    "                \"--ylabel\", \"[m]\",\n",
    "                \"--default-width\", \"0.3\",\n",
    "                \"--default-color\", \"#606060\",\n",
    "                \"--min-color-value\", \"0\",\n",
    "                \"--max-color-value\", \"15\",\n",
    "                \"--max-width-value\", \"15\",\n",
    "                \"--max-width\", \"1.3\",\n",
    "                \"--min-width\", \"0.3\",\n",
    "                \"--colormap\", \"jet\"\n",
    "            ]\n",
    "        )\n",
    "# ---------------------------------------------\n",
    "# Section 6 — SUMO Visualization PART3: Compare different simulation outputs\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Compare multiple simulation outputs - real vs augmented data generated model simulations\n",
    "# This allows comparison of the same metric across different scenarios\n",
    "# Scenarios are comparable if real vs augmented outputs show similar patterns\n",
    "\n",
    "def run_plot_net_dump_comparison(netfile, edgefiles, measures, labels, out, extra_args=None):\n",
    "    \"\"\"Call SUMO's plot_net_dump.py to compare multiple files.\"\"\"\n",
    "    # Check if input files exist\n",
    "    if not netfile or not netfile.exists():\n",
    "        print(f\"Network file {netfile} not found. Skipping comparison.\")\n",
    "        return None\n",
    "        \n",
    "    for edgefile in edgefiles:\n",
    "        if not edgefile.exists():\n",
    "            print(f\"Edge data file {edgefile} not found. Skipping comparison.\")\n",
    "            return None\n",
    "    \n",
    "    script = shutil.which('plot_net_dump.py')\n",
    "    if not script and PLOT_TOOLS_DIR:\n",
    "        candidate = PLOT_TOOLS_DIR / 'plot_net_dump.py'\n",
    "        if candidate.exists():\n",
    "            script = str(candidate)\n",
    "    if not script:\n",
    "        print('plot_net_dump.py not found. Please set SUMO_HOME or install SUMO tools.')\n",
    "        return None\n",
    "    \n",
    "    # Build input argument with multiple files\n",
    "    input_arg = \",\".join([str(f) for f in edgefiles])\n",
    "    \n",
    "    cmd = [script, \"-v\", \"-n\", str(netfile), \"--measures\", measures, \"-i\", input_arg, \"--output\", out]\n",
    "    \n",
    "    # Add labels if provided\n",
    "    if labels:\n",
    "        cmd.extend([\"--labels\", \",\".join(labels)])\n",
    "    \n",
    "    if extra_args:\n",
    "        cmd += extra_args\n",
    "    \n",
    "    print(\"Running comparison:\", \" \".join(cmd))\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=180)  # Longer timeout for comparisons\n",
    "        if result.returncode != 0:\n",
    "            print(f\"Error running plot_net_dump comparison: {result.stderr}\")\n",
    "            return None\n",
    "        return out\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"Comparison plotting timed out\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error in comparison plotting: {e}\")\n",
    "        return None\n",
    "\n",
    "# Group edgeoutput files by date for comparison\n",
    "def find_matching_files_by_date(real_files, augmented_files):\n",
    "    \"\"\"Find matching real and augmented files by date.\"\"\"\n",
    "    matches = []\n",
    "    \n",
    "    # Extract dates from real files\n",
    "    real_dates = {}\n",
    "    for f in real_files:\n",
    "        if 'edgedata.out' in f.name:\n",
    "            date_str = extract_date_from_path(f)\n",
    "            if date_str != \"unknown_date\":\n",
    "                real_dates[date_str] = f\n",
    "    \n",
    "    # Find matching augmented files\n",
    "    for f in augmented_files:\n",
    "        if 'edgedata.out' in f.name:\n",
    "            date_str = extract_date_from_path(f)\n",
    "            if date_str in real_dates:\n",
    "                matches.append((real_dates[date_str], f, date_str))\n",
    "    \n",
    "    return matches\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Section 6 - Comparing Real vs Augmented Outputs\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find matching files by date\n",
    "matching_pairs = find_matching_files_by_date(real_output_files, augmented_output_files)\n",
    "\n",
    "if matching_pairs:\n",
    "    print(f\"Found {len(matching_pairs)} date-matched file pairs for comparison\")\n",
    "    \n",
    "    for real_file, aug_file, date_str in matching_pairs:\n",
    "        print(f\"\\nComparing files for date: {date_str}\")\n",
    "        print(f\"  Real: {real_file.name}\")\n",
    "        print(f\"  Augmented: {aug_file.name}\")\n",
    "        \n",
    "        files_to_compare = [real_file, aug_file]\n",
    "        labels = [f\"Real_{date_str}\", f\"Augmented_{date_str}\"]\n",
    "        \n",
    "        # Comparison 1: A coloured city map showing vehicle movement/edge usage differences between scenarios for the same day.\n",
    "        \n",
    "        output_path = plots_dir / f'comparison_entered_{date_str}.png'\n",
    "        run_plot_net_dump_comparison(\n",
    "            net_xml,\n",
    "            files_to_compare,\n",
    "            \"entered,entered\",\n",
    "            labels,\n",
    "            str(output_path),\n",
    "            extra_args=[\n",
    "                \"--xlim\", \"900,16000\",\n",
    "                \"--ylim\", \"4500,16000\",\n",
    "                \"--xticks\", \"1000,16000,2500,5\",\n",
    "                \"--yticks\", \"2000,16000,2500,5\",\n",
    "                \"--xlabel\", \"[m]\",\n",
    "                \"--ylabel\", \"[m]\",\n",
    "                \"--default-width\", \"0.3\",\n",
    "                \"--default-color\", \"#606060\",\n",
    "                \"--min-color-value\", \"-100\",\n",
    "                \"--min-width-value\", \"-100\",            \n",
    "                \"--max-color-value\", \"100\",\n",
    "                \"--max-width-value\", \"100\",\n",
    "                \"--max-width\", \"1.3\",\n",
    "                \"--min-width\", \"0.3\",\n",
    "                \"--colormap\", \"#0:#0000c0,.25:#404080,.5:#808080,.75:#804040,1:#c00000\",\n",
    "                \"--legend-loc\", \"upper right\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Comparison 2: A coloured city map showing time loss differences between scenarios for the same day.\n",
    "        \n",
    "        output_path = plots_dir / f'comparison_timeloss_{date_str}.png'\n",
    "        run_plot_net_dump_comparison(\n",
    "            net_xml,\n",
    "            files_to_compare,\n",
    "            \"timeLoss,timeLoss\",\n",
    "            labels,\n",
    "            str(output_path),\n",
    "            extra_args=[\n",
    "                \"--xlim\", \"900,16000\",\n",
    "                \"--ylim\", \"4500,16000\",\n",
    "                \"--xticks\", \"1000,16000,2500,5\",\n",
    "                \"--yticks\", \"2000,16000,2500,5\",\n",
    "                \"--xlabel\", \"[m]\",\n",
    "                \"--ylabel\", \"[m]\",\n",
    "                \"--default-width\", \"0.3\",\n",
    "                \"--default-color\", \"#606060\",\n",
    "                \"--min-color-value\", \"-300\",\n",
    "                \"--min-width-value\", \"-300\",            \n",
    "                \"--max-color-value\", \"300\",  #5min\n",
    "                \"--max-width-value\", \"300\",\n",
    "                \"--max-width\", \"1.3\",\n",
    "                \"--min-width\", \"0.3\",\n",
    "                \"--colormap\", \"#0:#0000c0,.25:#404080,.5:#808080,.75:#804040,1:#c00000\", \n",
    "                \"--legend-loc\", \"upper right\"\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Comparison 3: A coloured city map showing mean speed differences between scenarios for the same day.\n",
    "        \n",
    "        output_path = plots_dir / f'comparison_speed_{date_str}.png'\n",
    "        run_plot_net_dump_comparison(\n",
    "            net_xml,\n",
    "            files_to_compare,\n",
    "            \"speed,speed\",\n",
    "            labels,\n",
    "            str(output_path),\n",
    "            extra_args=[\n",
    "                \"--xlim\", \"900,16000\",\n",
    "                \"--ylim\", \"4500,16000\",\n",
    "                \"--xticks\", \"1000,16000,2500,5\",\n",
    "                \"--yticks\", \"2000,16000,2500,5\",\n",
    "                \"--xlabel\", \"[m]\",\n",
    "                \"--ylabel\", \"[m]\",\n",
    "                \"--default-width\", \"0.3\",\n",
    "                \"--default-color\", \"#606060\",\n",
    "                \"--min-color-value\", \"-0.5\",\n",
    "                \"--min-width-value\", \"-0.5\",            \n",
    "                \"--max-color-value\", \"0.5\",\n",
    "                \"--max-width-value\", \"0.5\",\n",
    "                \"--max-width\", \"1.3\",\n",
    "                \"--min-width\", \"0.3\",\n",
    "                \"--colormap\", \"#0:#0000c0,.25:#404080,.5:#808080,.75:#804040,1:#c00000\",\n",
    "                \"--legend-loc\", \"upper right\"\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Comparison 4: A coloured city map showing vehicle teleportation differences between scenarios for the same day.\n",
    "        output_path = plots_dir / f'comparison_teleported_{date_str}.png'\n",
    "        run_plot_net_dump_comparison(\n",
    "            net_xml,\n",
    "            files_to_compare,\n",
    "            \"teleported,teleported\",\n",
    "            labels,\n",
    "            str(output_path),\n",
    "            extra_args=[\n",
    "                \"--xlim\", \"900,16000\",\n",
    "                \"--ylim\", \"4500,16000\",\n",
    "                \"--xticks\", \"1000,16000,2500,5\",\n",
    "                \"--yticks\", \"2000,16000,2500,5\",\n",
    "                \"--xlabel\", \"[m]\",\n",
    "                \"--ylabel\", \"[m]\",\n",
    "                \"--default-width\", \"0.3\",\n",
    "                \"--default-color\", \"#606060\",\n",
    "                \"--min-color-value\", \"-10\",\n",
    "                \"--min-width-value\", \"-10\",            \n",
    "                \"--max-color-value\", \"10\",\n",
    "                \"--max-width-value\", \"10\",\n",
    "                \"--max-width\", \"1.3\",\n",
    "                \"--min-width\", \"0.3\",\n",
    "                \"--colormap\", \"#0:#0000c0,.25:#404080,.5:#808080,.75:#804040,1:#c00000\",\n",
    "                \"--legend-loc\", \"upper right\"\n",
    "            ]\n",
    "        )\n",
    "else:\n",
    "    print(\"No matching date pairs found for comparison between real and augmented outputs\")\n",
    "\n",
    "# Summary output\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Final Summary:\")\n",
    "print(f\"Plots directory: {plots_dir}\")\n",
    "print(f\"Total real output files found: {len(real_output_files)}\")\n",
    "print(f\"Total augmented output files found: {len(augmented_output_files)}\")\n",
    "print(f\"Date-matched pairs for comparison: {len(matching_pairs)}\")\n",
    "\n",
    "# Count files by type and show dates found\n",
    "file_types = {}\n",
    "dates_found = set()\n",
    "\n",
    "for f in real_output_files:\n",
    "    date_str = extract_date_from_path(f)\n",
    "    dates_found.add(date_str)\n",
    "    \n",
    "    for file_type in ['vehroute', 'summary', 'tripinfo', 'detector.out', 'edgedata.out', 'fcd']:\n",
    "        if file_type in f.name:\n",
    "            if file_type not in file_types:\n",
    "                file_types[file_type] = 0\n",
    "            file_types[file_type] += 1\n",
    "            break\n",
    "\n",
    "print(\"Files by type:\")\n",
    "for file_type, count in file_types.items():\n",
    "    print(f\"  {file_type}: {count}\")\n",
    "\n",
    "print(\"Dates found in file paths:\")\n",
    "for date in sorted(dates_found):\n",
    "    print(f\"  {date}\")\n",
    "\n",
    "print(\"Plot generation completed!\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
